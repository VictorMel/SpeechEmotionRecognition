{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0392a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "config = os.path.join('configs','resnet_mfcc.yaml')\n",
    "run_name = 'debug_flag'\n",
    "max_samples = 20\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122cab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML config and display top-level sections\n",
    "import os, pprint, sys, subprocess\n",
    "\n",
    "# Robust import of yaml with auto-install fallback\n",
    "try:\n",
    "    import yaml\n",
    "except ModuleNotFoundError:\n",
    "    print(\"PyYAML not found in current kernel. Attempting installation...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'PyYAML'])\n",
    "    import yaml\n",
    "    print(\"PyYAML installed successfully.\")\n",
    "\n",
    "assert os.path.isfile(config), f\"Config file not found: {config}\"\n",
    "with open(config, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Keep cfg in notebook variable for later experiment use\n",
    "cfg_dict = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a428b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'root': 'D:\\\\Projects\\\\Technion\\\\SpeechEmotionRecognition\\\\data',\n",
       "  'feature_type': 'mfcc',\n",
       "  'feature_params': {'n_mfcc': 40, 'add_delta': True, 'add_delta2': True},\n",
       "  'sr': 16000,\n",
       "  'cache_dir': 'cache_features/mfcc',\n",
       "  'fixed_frames': 256},\n",
       " 'model': {'name': 'resnet',\n",
       "  'params': {'in_channels': 1,\n",
       "   'base_channels': 32,\n",
       "   'num_classes': 8,\n",
       "   'depth': 4}},\n",
       " 'train': {'batch_size': 32,\n",
       "  'epochs': 30,\n",
       "  'optimizer': {'lr': 0.001, 'weight_decay': 0.0005},\n",
       "  'amp': True,\n",
       "  'accumulate_steps': 1,\n",
       "  'early_patience': 10},\n",
       " 'logging': {'log_dir': 'logs/resnet_mfcc_run1',\n",
       "  'checkpoint_dir': 'checkpoints/resnet_mfcc_run1',\n",
       "  'tensorboard': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a692b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import EmotionDataset, DatasetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4d36c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 12162 files.\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "ds_cfg = DatasetConfig(\n",
    "    data_root=cfg_dict['data']['root'],\n",
    "    feature_name=cfg_dict['data']['feature_type'],\n",
    "    target_sr=cfg_dict['data'].get('sr', 16000),\n",
    "    cache_dir=cfg_dict['data'].get('cache_dir', f\"cache_features/{cfg_dict['data']['feature_type']}\"),\n",
    "    feature_params=cfg_dict['data'].get('feature_params', {}),\n",
    "    file_ext=cfg_dict['data'].get('ext', '.wav'),\n",
    "    fixed_frames=cfg_dict['data'].get('fixed_frames', None),\n",
    ")\n",
    "ds_work = EmotionDataset(ds_cfg)\n",
    "print(f\"Discovered {len(ds_work)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e7978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8b147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple split\n",
    "indices = torch.randperm(len(ds_work))\n",
    "n = len(indices)\n",
    "train_end = int(0.8 * n)\n",
    "val_end = int(0.9 * n)\n",
    "train_idx, val_idx, test_idx = indices[:train_end], indices[train_end:val_end], indices[val_end:]\n",
    "ds_train = torch.utils.data.Subset(ds_work, train_idx)\n",
    "ds_val = torch.utils.data.Subset(ds_work, val_idx)\n",
    "ds_test = torch.utils.data.Subset(ds_work, test_idx)\n",
    "\n",
    "batch_size = cfg_dict['train']['batch_size']\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=cfg_dict['train'].get('num_workers', 0))\n",
    "dl_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=cfg_dict['train'].get('num_workers', 0))\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=cfg_dict['train'].get('num_workers', 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

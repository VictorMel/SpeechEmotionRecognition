{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f2421e",
   "metadata": {},
   "source": [
    "<!-- filepath: d:\\Projects\\Technion\\EmotionDetection\\migration_api_usage.ipynb -->\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "# EmotionDetection Migration & Archival\n",
    "This notebook archives legacy Python modules and notebooks into the `old` directory and demonstrates usage of the new modular API (features, datasets, models, training). Set `dry_run=True` first to preview operations safely.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 1. Configure Paths and Parameters\n",
    "from pathlib import Path\n",
    "import shutil, json, ast, difflib, datetime, argparse, sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "BASE_DIR = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "ARCHIVE_DIR = BASE_DIR / 'old'\n",
    "TARGET_EXTS = ['.py', '.ipynb']\n",
    "EXCLUDE_DIR_NAMES = {'old', 'models', 'training', 'experiments', 'configs'}  # keep new API dirs\n",
    "DRY_RUN = True  # change to False after validating plan\n",
    "VERBOSE = True\n",
    "\n",
    "# Legacy file name heuristics (explicit list for precision)\n",
    "LEGACY_FILES = {\n",
    "    'DataManipulation.py', 'DataVisualization.py', 'DeepLearningBlocks.py', 'DeepLearningPyTorch.py'\n",
    "}\n",
    "\n",
    "# Notebook pattern\n",
    "NOTEBOOK_PREFIX = 'prj_SER_'\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 2. Enumerate Legacy Files (Notebook + Code Files)\n",
    "import pandas as pd\n",
    "\n",
    "legacy_candidates = []\n",
    "for p in BASE_DIR.iterdir():\n",
    "    if p.name in EXCLUDE_DIR_NAMES:\n",
    "        continue\n",
    "    if p.is_file():\n",
    "        if (p.suffix in TARGET_EXTS) and (p.name in LEGACY_FILES or p.name.startswith(NOTEBOOK_PREFIX)):\n",
    "            legacy_candidates.append(p)\n",
    "\n",
    "# Also include files deeper (only top-level notebooks expected)\n",
    "for p in BASE_DIR.rglob('*'):\n",
    "    if any(part in EXCLUDE_DIR_NAMES for part in p.parts):\n",
    "        continue\n",
    "    if p.is_file() and (p.suffix in TARGET_EXTS) and (p.name.startswith(NOTEBOOK_PREFIX)) and (p.parent == BASE_DIR):\n",
    "        if p not in legacy_candidates:\n",
    "            legacy_candidates.append(p)\n",
    "\n",
    "summary = pd.DataFrame({'path': [str(p) for p in legacy_candidates], 'ext': [p.suffix for p in legacy_candidates]})\n",
    "print(f\"Found {len(summary)} legacy artifacts\")\n",
    "summary.groupby('ext').size().rename('count')\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 3. Create Archive Directory If Missing\n",
    "if VERBOSE:\n",
    "    print(f\"Archive dir: {ARCHIVE_DIR}\")\n",
    "if not DRY_RUN:\n",
    "    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    print(\"[DRY_RUN] Would create archive directory if absent.\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 4. Move Files to Archive (Atomic Operations)\n",
    "errors = []\n",
    "moved = []\n",
    "for src in legacy_candidates:\n",
    "    dst = ARCHIVE_DIR / src.name\n",
    "    if VERBOSE:\n",
    "        print(f\"Planning move: {src.name} -> {dst}\")\n",
    "    if DRY_RUN:\n",
    "        continue\n",
    "    try:\n",
    "        if dst.exists():\n",
    "            # Avoid overwriting inadvertently; append timestamp\n",
    "            stamped = ARCHIVE_DIR / f\"{src.stem}_dup_{int(datetime.datetime.utcnow().timestamp())}{src.suffix}\"\n",
    "            shutil.move(str(src), stamped)\n",
    "            moved.append((src, stamped))\n",
    "        else:\n",
    "            shutil.move(str(src), dst)\n",
    "            moved.append((src, dst))\n",
    "    except Exception as e:\n",
    "        errors.append((src, repr(e)))\n",
    "\n",
    "print(f\"Moves completed (dry_run={DRY_RUN}).\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 5. Delete Originals After Successful Move\n",
    "# (Since we used shutil.move originals are already removed if DRY_RUN=False)\n",
    "if DRY_RUN:\n",
    "    print(\"[DRY_RUN] Skipping deletion (handled inherently by move).\")\n",
    "else:\n",
    "    print(\"Deletion implicit in move; verifying...\")\n",
    "    for src, dst in moved:\n",
    "        if src.exists() and dst.exists():\n",
    "            errors.append((src, 'Original still exists after move'))\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 6. Post-Move Verification and Reporting\n",
    "report = {\n",
    "    'timestamp': datetime.datetime.utcnow().isoformat(),\n",
    "    'dry_run': DRY_RUN,\n",
    "    'moved_count': len(moved) if not DRY_RUN else 0,\n",
    "    'errors': errors,\n",
    "    'files_planned': [str(p) for p in legacy_candidates]\n",
    "}\n",
    "print(json.dumps(report, indent=2))\n",
    "if not DRY_RUN:\n",
    "    with open(ARCHIVE_DIR / 'archive_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "else:\n",
    "    print('[DRY_RUN] Report not written.')\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 7. Clean Up Empty Source Directories (not expected for flat layout)\n",
    "if DRY_RUN:\n",
    "    print('[DRY_RUN] Skipping directory cleanup.')\n",
    "else:\n",
    "    for d in sorted(BASE_DIR.iterdir()):\n",
    "        if d.is_dir() and d.name != 'old':\n",
    "            try:\n",
    "                if not any(d.iterdir()):\n",
    "                    d.rmdir()\n",
    "                    if VERBOSE:\n",
    "                        print(f'Removed empty directory: {d}')\n",
    "            except OSError:\n",
    "                pass\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 8. Generate Migration Notebook File Programmatically\n",
    "MIGRATION_NOTEBOOK_PATH = BASE_DIR / 'migration.ipynb'\n",
    "if DRY_RUN:\n",
    "    print('[DRY_RUN] Would generate migration.ipynb')\n",
    "else:\n",
    "    nb_struct = {\n",
    "        'cells': [],\n",
    "        'metadata': {\n",
    "            'kernelspec': {\n",
    "                'name': 'python3',\n",
    "                'language': 'python',\n",
    "                'display_name': 'Python 3'\n",
    "            },\n",
    "            'language_info': {'name': 'python'}\n",
    "        },\n",
    "        'nbformat': 4,\n",
    "        'nbformat_minor': 5\n",
    "    }\n",
    "    with open(MIGRATION_NOTEBOOK_PATH, 'w') as f:\n",
    "        json.dump(nb_struct, f)\n",
    "    print(f'Created empty notebook at {MIGRATION_NOTEBOOK_PATH}')\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 9. Populate Migration Notebook: New API Imports (Demonstration inline instead of editing separate file)\n",
    "from importlib import import_module\n",
    "\n",
    "try:\n",
    "    features_mod = import_module('audio_features')\n",
    "    datasets_mod = import_module('datasets')\n",
    "    models_mod = import_module('models')\n",
    "    training_mod = import_module('training.loops')\n",
    "    print('Imported new modular API successfully.')\n",
    "    print('Features available:', features_mod.available_features())\n",
    "    print('Models available:', models_mod.available_models())\n",
    "except Exception as e:\n",
    "    print('Import failed (ensure running from EmotionDetection root):', e)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Old vs New API Overview\n",
    "Below we show a conceptual mapping. The old `TrainModel` + `RunEpoch` functions are now replaced by `train_loop` with a `TrainConfig` dataclass.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 10. Side-by-Side Old vs New API Usage (Conceptual)\n",
    "old_example = \"\"\"\n",
    "from DeepLearningPyTorch import TrainModel, RunEpoch, EvaluateModel\n",
    "# oModel, lTrainLoss, ... = TrainModel(model, dlTrain, dlVal, optimizer, nEpochs, loss_fn, score_fn)\n",
    "\"\"\"\n",
    "\n",
    "new_example = \"\"\"\n",
    "from training.loops import TrainConfig, train_loop\n",
    "cfg = TrainConfig(epochs=1, lr=1e-4, device='cpu')\n",
    "res = train_loop(model, train_loader, val_loader, loss_fn, score_fn, cfg)\n",
    "\"\"\"\n",
    "print('OLD API:\\n', old_example)\n",
    "print('NEW API:\\n', new_example)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 11. Batch Refactor Helper (AST based rename demonstration)\n",
    "RENAME_MAP = {\n",
    "    'TrainModel': 'train_loop',\n",
    "    'RunEpoch': 'train_loop',  # conceptual replacement\n",
    "    'EvaluateModel': 'train_loop'  # using separate evaluation pipeline later\n",
    "}\n",
    "\n",
    "def refactor_source(src: str, rename_map: dict) -> str:\n",
    "    class Renamer(ast.NodeTransformer):\n",
    "        def visit_Name(self, node: ast.Name):\n",
    "            if node.id in rename_map:\n",
    "                return ast.copy_location(ast.Name(id=rename_map[node.id], ctx=node.ctx), node)\n",
    "            return node\n",
    "    tree = ast.parse(src)\n",
    "    tree = Renamer().visit(tree)\n",
    "    ast.fix_missing_locations(tree)\n",
    "    return src if DRY_RUN else ast.unparse(tree)\n",
    "\n",
    "sample_old_code = \"\"\"\n",
    "from DeepLearningPyTorch import TrainModel\\nTrainModel(model, dlTrain, dlVal, opt, 10, loss_fn, score_fn)\\n\"\"\"\n",
    "if DRY_RUN:\n",
    "    # Show textual diff only\n",
    "    transformed = sample_old_code.replace('TrainModel', 'train_loop')\n",
    "else:\n",
    "    transformed = refactor_source(sample_old_code, RENAME_MAP)\n",
    "\n",
    "print('--- Diff Preview ---')\n",
    "for line in difflib.unified_diff(sample_old_code.splitlines(), transformed.splitlines(), lineterm=''):\n",
    "    print(line)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 12. Logging and Dry-Run Mode Helper\n",
    "def log(msg: str):\n",
    "    if VERBOSE:\n",
    "        print(msg)\n",
    "\n",
    "log(f\"Dry run mode is {'ON' if DRY_RUN else 'OFF'}\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 13. Simple pytest Test Stubs for New API\n",
    "TESTS_DIR = BASE_DIR / 'tests'\n",
    "if DRY_RUN:\n",
    "    print('[DRY_RUN] Would create tests/test_new_api.py')\n",
    "else:\n",
    "    TESTS_DIR.mkdir(exist_ok=True)\n",
    "    test_file = TESTS_DIR / 'test_new_api.py'\n",
    "    test_src = \"\"\"import importlib\\n\\nfeatures = importlib.import_module('audio_features')\\nmodels = importlib.import_module('models')\\n\\ndef test_feature_registry_presence():\\n    assert len(features.available_features()) >= 1\\n\\ndef test_model_registry_presence():\\n    assert len(models.available_models()) >= 1\\n\"\"\"\n",
    "    test_file.write_text(test_src)\n",
    "    print('Created', test_file)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 14. Optional CLI Argument Parsing Inside Notebook\n",
    "if '__file__' not in globals():  # Only when executed as a script via nbconvert/papermill\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dry_run', action='store_true', help='Perform dry run without moving files')\n",
    "    parser.add_argument('--verbose', action='store_true', help='Verbose logging')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    DRY_RUN = args.dry_run or DRY_RUN\n",
    "    VERBOSE = args.verbose or VERBOSE\n",
    "    log(f\"Args applied: dry_run={DRY_RUN}, verbose={VERBOSE}\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# 15. Persist Execution Metadata\n",
    "meta = {\n",
    "    'start_time': report.get('timestamp'),\n",
    "    'end_time': datetime.datetime.utcnow().isoformat(),\n",
    "    'planned_files': report.get('files_planned'),\n",
    "    'dry_run': DRY_RUN,\n",
    "    'moved_count': report.get('moved_count'),\n",
    "    'error_count': len(report.get('errors', []))\n",
    "}\n",
    "if DRY_RUN:\n",
    "    print('[DRY_RUN] Would write metadata.json')\n",
    "else:\n",
    "    with open(ARCHIVE_DIR / 'metadata.json', 'w') as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "print(json.dumps(meta, indent=2))\n",
    "</VSCode.Cell>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
